{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f38666-c16d-4e1e-815d-e507d83334e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a8ce86-58f1-4bcf-8c4f-91a059666a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "from ogb.utils import smiles2graph\n",
    "from ogb.utils.torch_util import replace_numpy_with_torchtensor\n",
    "from ogb.utils.url import decide_download, download_url, extract_zip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class PygTox21Dataset(InMemoryDataset):\n",
    "    def __init__(self, root = '../../dataset', smiles2graph = smiles2graph, transform=None, pre_transform = None):\n",
    "        self.original_root = root\n",
    "        self.smiles2graph = smiles2graph\n",
    "        self.folder = osp.join(root, 'Tox21')\n",
    "        self.version = 1\n",
    "        \n",
    "        super(PygTox21Dataset, self).__init__(self.folder, transform, pre_transform)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return 'data.csv.gz'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'geometric_data_processed.pt'\n",
    "\n",
    "    def process(self):\n",
    "        data_df = pd.read_csv(osp.join(self.raw_dir, 'data.csv.gz'))\n",
    "        smiles_list = data_df['smiles']\n",
    "        task = ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD',\n",
    "                'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
    "        labels = data_df[task]\n",
    "        labels = labels.replace(0, -1)\n",
    "        # convert nan to 0\n",
    "        labels = labels.fillna(0)\n",
    "        labels = labels.values\n",
    "        print('Converting SMILES strings into graphs...')\n",
    "        data_list = []\n",
    "        data_idx = []\n",
    "        for i in tqdm(range(len(smiles_list))):\n",
    "            data = Data()\n",
    "\n",
    "            smiles = smiles_list[i]\n",
    "            label = labels[i]\n",
    "            graph = self.smiles2graph(smiles)\n",
    "            \n",
    "            assert(len(graph['edge_feat']) == graph['edge_index'].shape[1])\n",
    "            assert(len(graph['node_feat']) == graph['num_nodes'])\n",
    "\n",
    "            data.__num_nodes__ = int(graph['num_nodes'])\n",
    "            data.edge_index = torch.from_numpy(graph['edge_index']).to(torch.int64)\n",
    "            data.edge_attr = torch.from_numpy(graph['edge_feat']).to(torch.int64)\n",
    "            data.x = torch.from_numpy(graph['node_feat']).to(torch.int64)\n",
    "            data.y = torch.Tensor([label])\n",
    "\n",
    "            data_list.append(data)\n",
    "            data_idx.append(i)\n",
    "        self.data_idx = data_idx\n",
    "        print(len(data_list))\n",
    "        # double-check prediction target\n",
    "        split_dict = self.get_idx_split()\n",
    "        \n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "\n",
    "        print('Saving...')\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        \n",
    "    \n",
    "    def get_idx_split(self):\n",
    "        return torch.load('../../dataset/Tox21/processed/split_idx.pt')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = PygTox21Dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7650d474-41ba-46b5-8eac-7fcd80fdd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch_geometric.datasets\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from ogb.lsc.pcqm4m_pyg import PygPCQM4MDataset\n",
    "import pyximport\n",
    "\n",
    "pyximport.install(setup_args={'include_dirs': np.get_include()})\n",
    "import algos\n",
    "\n",
    "\n",
    "def convert_to_single_emb(x, offset=512):\n",
    "    feature_num = x.size(1) if len(x.size()) > 1 else 1\n",
    "    feature_offset = 1 + \\\n",
    "        torch.arange(0, feature_num * offset, offset, dtype=torch.long)\n",
    "    x = x + feature_offset\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_item(item):\n",
    "    edge_attr, edge_index, x = item.edge_attr, item.edge_index, item.x\n",
    "    N = x.size(0)\n",
    "    x = convert_to_single_emb(x)\n",
    "\n",
    "    # node adj matrix [N, N] bool\n",
    "    adj = torch.zeros([N, N], dtype=torch.bool)\n",
    "    adj[edge_index[0, :], edge_index[1, :]] = True\n",
    "\n",
    "    # edge feature here\n",
    "    if len(edge_attr.size()) == 1:\n",
    "        edge_attr = edge_attr[:, None]\n",
    "    attn_edge_type = torch.zeros([N, N, edge_attr.size(-1)], dtype=torch.long)\n",
    "    attn_edge_type[edge_index[0, :], edge_index[1, :]\n",
    "                   ] = convert_to_single_emb(edge_attr) + 1\n",
    "\n",
    "    shortest_path_result, path = algos.floyd_warshall(adj.numpy())\n",
    "    max_dist = np.amax(shortest_path_result)\n",
    "    edge_input = algos.gen_edge_input(max_dist, path, attn_edge_type.numpy())\n",
    "    spatial_pos = torch.from_numpy((shortest_path_result)).long()\n",
    "    attn_bias = torch.zeros(\n",
    "        [N + 1, N + 1], dtype=torch.float)  # with graph token\n",
    "\n",
    "    # combine\n",
    "    item.x = x\n",
    "    item.adj = adj\n",
    "    item.attn_bias = attn_bias\n",
    "    item.attn_edge_type = attn_edge_type\n",
    "    item.spatial_pos = spatial_pos\n",
    "    item.in_degree = adj.long().sum(dim=1).view(-1)\n",
    "    item.out_degree = adj.long().sum(dim=0).view(-1)\n",
    "    item.edge_input = torch.from_numpy(edge_input).long()\n",
    "\n",
    "    return item\n",
    "\n",
    "\n",
    "\n",
    "class MyPygTox21Dataset(PygTox21Dataset):\n",
    "    def download(self):\n",
    "        super(MyPygTox21Dataset, self).download()\n",
    "\n",
    "    def process(self):\n",
    "        super(MyPygTox21Dataset, self).process()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            item = self.get(self.indices()[idx])\n",
    "            item.idx = idx\n",
    "            return preprocess_item(item)\n",
    "        else:\n",
    "            return self.index_select(idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27231bd7-5817-40e7-8c2e-85ee511d90be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "from collator import collator\n",
    "\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import ogb\n",
    "import ogb.lsc\n",
    "import ogb.graphproppred\n",
    "from functools import partial\n",
    "import random\n",
    "\n",
    "dataset = None\n",
    "\n",
    "\n",
    "def get_dataset(dataset_name='abaaba'):\n",
    "    global dataset\n",
    "    if dataset is not None:\n",
    "        return dataset\n",
    "\n",
    "    if dataset_name == 'Tox21':\n",
    "        dataset = {\n",
    "            'dataset': MyPygTox21Dataset(root='../../dataset'),\n",
    "            'max_node': 128,\n",
    "            'metric_mode': 'max',\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    print(f' > {dataset_name} loaded!')\n",
    "    print(dataset)\n",
    "    print(f' > dataset info ends')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class GraphDataModule(LightningDataModule):\n",
    "    name = \"OGB-GRAPH\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str = 'Tox21',\n",
    "        num_workers: int = 0,\n",
    "        batch_size: int = 256,\n",
    "        seed: int = 42,\n",
    "        multi_hop_max_dist: int = 5,\n",
    "        spatial_pos_max: int = 1024,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = get_dataset(self.dataset_name)\n",
    "\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_train = ...\n",
    "        self.dataset_val = ...\n",
    "        self.multi_hop_max_dist = multi_hop_max_dist\n",
    "        self.spatial_pos_max = spatial_pos_max\n",
    "\n",
    "    def setup(self, stage: str = None):\n",
    "        if self.dataset_name == 'ZINC':\n",
    "            self.dataset_train = self.dataset['train_dataset']\n",
    "            self.dataset_val = self.dataset['valid_dataset']\n",
    "            self.dataset_test = self.dataset['test_dataset']\n",
    "        else:\n",
    "            split_idx = self.dataset['dataset'].get_idx_split()\n",
    "            self.dataset_train = self.dataset['dataset'][split_idx[\"train\"]]\n",
    "            self.dataset_val = self.dataset['dataset'][split_idx[\"valid\"]]\n",
    "            self.dataset_test = self.dataset['dataset'][split_idx[\"test\"]]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.dataset_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=partial(collator, max_node=get_dataset(self.dataset_name)[\n",
    "                               'max_node'], multi_hop_max_dist=self.multi_hop_max_dist, spatial_pos_max=self.spatial_pos_max),\n",
    "        )\n",
    "        print('len(train_dataloader)', len(loader))\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.dataset_val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=False,\n",
    "            collate_fn=partial(collator, max_node=get_dataset(self.dataset_name)[\n",
    "                               'max_node'], multi_hop_max_dist=self.multi_hop_max_dist, spatial_pos_max=self.spatial_pos_max),\n",
    "        )\n",
    "        print('len(val_dataloader)', len(loader))\n",
    "        return loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.dataset_test,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=False,\n",
    "            collate_fn=partial(collator, max_node=get_dataset(self.dataset_name)[\n",
    "                               'max_node'], multi_hop_max_dist=self.multi_hop_max_dist, spatial_pos_max=self.spatial_pos_max),\n",
    "        )\n",
    "        print('len(test_dataloader)', len(loader))\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25546446-76db-4963-9c84-8d99c5d46792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800a0f33-9779-4821-9b63-ca224a5e7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lr import PolynomialDecayLR\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from flag import flag_bounded\n",
    "\n",
    "\n",
    "def init_params(module, n_layers):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        module.weight.data.normal_(mean=0.0, std=0.02 / math.sqrt(n_layers))\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "    if isinstance(module, nn.Embedding):\n",
    "        module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "class Graphormer(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_layers,\n",
    "        num_heads,\n",
    "        hidden_dim,\n",
    "        dropout_rate,\n",
    "        intput_dropout_rate,\n",
    "        weight_decay,\n",
    "        ffn_dim,\n",
    "        dataset_name,\n",
    "        warmup_updates,\n",
    "        tot_updates,\n",
    "        peak_lr,\n",
    "        end_lr,\n",
    "        edge_type,\n",
    "        multi_hop_max_dist,\n",
    "        attention_dropout_rate,\n",
    "        flag=False,\n",
    "        flag_m=3,\n",
    "        flag_step_size=1e-3,\n",
    "        flag_mag=1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        if dataset_name == 'ZINC':\n",
    "            self.atom_encoder = nn.Embedding(64, hidden_dim, padding_idx=0)\n",
    "            self.edge_encoder = nn.Embedding(64, num_heads, padding_idx=0)\n",
    "            self.edge_type = edge_type\n",
    "            if self.edge_type == 'multi_hop':\n",
    "                self.edge_dis_encoder = nn.Embedding(\n",
    "                    40 * num_heads * num_heads, 1)\n",
    "            self.spatial_pos_encoder = nn.Embedding(40, num_heads, padding_idx=0)\n",
    "            self.in_degree_encoder = nn.Embedding(\n",
    "                64, hidden_dim, padding_idx=0)\n",
    "            self.out_degree_encoder = nn.Embedding(\n",
    "                64, hidden_dim, padding_idx=0)\n",
    "        else:\n",
    "            self.atom_encoder = nn.Embedding(\n",
    "                512 * 9 + 1, hidden_dim, padding_idx=0)\n",
    "            self.edge_encoder = nn.Embedding(\n",
    "                512 * 3 + 1, num_heads, padding_idx=0)\n",
    "            self.edge_type = edge_type\n",
    "            if self.edge_type == 'multi_hop':\n",
    "                self.edge_dis_encoder = nn.Embedding(\n",
    "                    128 * num_heads * num_heads, 1)\n",
    "            self.spatial_pos_encoder = nn.Embedding(512, num_heads, padding_idx=0)\n",
    "            self.in_degree_encoder = nn.Embedding(\n",
    "                512, hidden_dim, padding_idx=0)\n",
    "            self.out_degree_encoder = nn.Embedding(\n",
    "                512, hidden_dim, padding_idx=0)\n",
    "\n",
    "        self.input_dropout = nn.Dropout(intput_dropout_rate)\n",
    "        encoders = [EncoderLayer(hidden_dim, ffn_dim, dropout_rate, attention_dropout_rate, num_heads)\n",
    "                    for _ in range(n_layers)]\n",
    "        self.layers = nn.ModuleList(encoders)\n",
    "        self.final_ln = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        if dataset_name == 'PCQM4M-LSC':\n",
    "            self.out_proj = nn.Linear(hidden_dim, 1)\n",
    "        else:\n",
    "            self.downstream_out_proj = nn.Linear(\n",
    "                hidden_dim, 12)\n",
    "\n",
    "        self.graph_token = nn.Embedding(1, hidden_dim)\n",
    "        self.graph_token_virtual_distance = nn.Embedding(1, num_heads)\n",
    "\n",
    "        self.evaluator = torchmetrics.AUROC()\n",
    "        self.metric = 'AUROC'\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        self.focal_loss = FocalLoss()\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        self.warmup_updates = warmup_updates\n",
    "        self.tot_updates = tot_updates\n",
    "        self.peak_lr = peak_lr\n",
    "        self.end_lr = end_lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.multi_hop_max_dist = multi_hop_max_dist\n",
    "\n",
    "        self.flag = flag\n",
    "        self.flag_m = flag_m\n",
    "        self.flag_step_size = flag_step_size\n",
    "        self.flag_mag = flag_mag\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.automatic_optimization = not self.flag\n",
    "        self.apply(lambda module: init_params(module, n_layers=n_layers))\n",
    "\n",
    "    def forward(self, batched_data, perturb=None):\n",
    "        attn_bias, spatial_pos, x = batched_data.attn_bias, batched_data.spatial_pos, batched_data.x\n",
    "        in_degree, out_degree = batched_data.in_degree, batched_data.in_degree\n",
    "        edge_input, attn_edge_type = batched_data.edge_input, batched_data.attn_edge_type\n",
    "        # graph_attn_bias\n",
    "        n_graph, n_node = x.size()[:2]\n",
    "        graph_attn_bias = attn_bias.clone()\n",
    "        graph_attn_bias = graph_attn_bias.unsqueeze(1).repeat(\n",
    "            1, self.num_heads, 1, 1)  # [n_graph, n_head, n_node+1, n_node+1]\n",
    "\n",
    "        # spatial pos\n",
    "        # [n_graph, n_node, n_node, n_head] -> [n_graph, n_head, n_node, n_node]\n",
    "        spatial_pos_bias = self.spatial_pos_encoder(spatial_pos).permute(0, 3, 1, 2)\n",
    "        graph_attn_bias[:, :, 1:, 1:] = graph_attn_bias[:,\n",
    "                                                        :, 1:, 1:] + spatial_pos_bias\n",
    "        # reset spatial pos here\n",
    "        t = self.graph_token_virtual_distance.weight.view(1, self.num_heads, 1)\n",
    "        graph_attn_bias[:, :, 1:, 0] = graph_attn_bias[:, :, 1:, 0] + t\n",
    "        graph_attn_bias[:, :, 0, :] = graph_attn_bias[:, :, 0, :] + t\n",
    "\n",
    "        # edge feature\n",
    "        if self.edge_type == 'multi_hop':\n",
    "            spatial_pos_ = spatial_pos.clone()\n",
    "            spatial_pos_[spatial_pos_ == 0] = 1  # set pad to 1\n",
    "            # set 1 to 1, x > 1 to x - 1\n",
    "            spatial_pos_ = torch.where(spatial_pos_ > 1, spatial_pos_ - 1, spatial_pos_)\n",
    "            if self.multi_hop_max_dist > 0:\n",
    "                spatial_pos_ = spatial_pos_.clamp(0, self.multi_hop_max_dist)\n",
    "                edge_input = edge_input[:, :, :, :self.multi_hop_max_dist, :]\n",
    "            # [n_graph, n_node, n_node, max_dist, n_head]\n",
    "            edge_input = self.edge_encoder(edge_input).mean(-2)\n",
    "            max_dist = edge_input.size(-2)\n",
    "            edge_input_flat = edge_input.permute(\n",
    "                3, 0, 1, 2, 4).reshape(max_dist, -1, self.num_heads)\n",
    "            edge_input_flat = torch.bmm(edge_input_flat, self.edge_dis_encoder.weight.reshape(\n",
    "                -1, self.num_heads, self.num_heads)[:max_dist, :, :])\n",
    "            edge_input = edge_input_flat.reshape(\n",
    "                max_dist, n_graph, n_node, n_node, self.num_heads).permute(1, 2, 3, 0, 4)\n",
    "            edge_input = (edge_input.sum(-2) /\n",
    "                          (spatial_pos_.float().unsqueeze(-1))).permute(0, 3, 1, 2)\n",
    "        else:\n",
    "            # [n_graph, n_node, n_node, n_head] -> [n_graph, n_head, n_node, n_node]\n",
    "            edge_input = self.edge_encoder(\n",
    "                attn_edge_type).mean(-2).permute(0, 3, 1, 2)\n",
    "\n",
    "        graph_attn_bias[:, :, 1:, 1:] = graph_attn_bias[:,\n",
    "                                                        :, 1:, 1:] + edge_input\n",
    "        graph_attn_bias = graph_attn_bias + attn_bias.unsqueeze(1)  # reset\n",
    "\n",
    "        # node feauture + graph token\n",
    "        node_feature = self.atom_encoder(x).sum(\n",
    "            dim=-2)           # [n_graph, n_node, n_hidden]\n",
    "        if self.flag and perturb is not None:\n",
    "            node_feature += perturb\n",
    "\n",
    "        node_feature = node_feature + \\\n",
    "            self.in_degree_encoder(in_degree) + \\\n",
    "            self.out_degree_encoder(out_degree)\n",
    "        graph_token_feature = self.graph_token.weight.unsqueeze(\n",
    "            0).repeat(n_graph, 1, 1)\n",
    "        graph_node_feature = torch.cat(\n",
    "            [graph_token_feature, node_feature], dim=1)\n",
    "\n",
    "        # transfomrer encoder\n",
    "        output = self.input_dropout(graph_node_feature)\n",
    "        for enc_layer in self.layers:\n",
    "            output = enc_layer(output, graph_attn_bias)\n",
    "        output = self.final_ln(output)\n",
    "\n",
    "        # output part\n",
    "        if self.dataset_name == 'PCQM4M-LSC':\n",
    "            # get whole graph rep\n",
    "            output = self.out_proj(output[:, 0, :])\n",
    "        else:\n",
    "            output = self.downstream_out_proj(output[:, 0, :])\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batched_data, batch_idx):\n",
    "        y_hat = self(batched_data)\n",
    "        y_gt = batched_data.y.view(y_hat.shape).to(torch.float64)\n",
    "        ######\n",
    "        #Whether y is non-null or not.\n",
    "        is_valid = y_gt**2 > 0\n",
    "        #Loss matrix\n",
    "        loss_mat = self.loss_fn(y_hat.double(), (y_gt + 1) / 2)     \n",
    "        #loss_mat = self.focal_loss(y_hat.double(), (y_gt + 1) / 2)\n",
    "        #pt = torch.exp(-loss_mat)\n",
    "        #loss_mat = 1 * (1-pt)**2 * loss_mat\n",
    "        #loss matrix after removing null target\n",
    "        loss_mat = torch.where(is_valid, loss_mat, torch.zeros(loss_mat.shape).to(loss_mat.device).to(loss_mat.dtype))\n",
    "        loss = torch.sum(loss_mat) / (torch.sum(is_valid))\n",
    "        \"\"\"for name, parms in self.named_parameters():\n",
    "            print('-->name:', name, '-->grad_requirs:',parms.requires_grad, ' -->grad_value:',parms.grad)\"\"\"\n",
    "        ######\n",
    "        #loss = self.loss_fn(y_hat, y_gt)\n",
    "        self.log('train_loss', loss, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batched_data, batch_idx):\n",
    "        if self.dataset_name in ['PCQM4M-LSC', 'ZINC']:\n",
    "            y_pred = self(batched_data).view(-1)\n",
    "            y_true = batched_data.y.view(-1)\n",
    "        else:\n",
    "            y_pred = self(batched_data)\n",
    "            y_true = batched_data.y\n",
    "        return {\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y_true,\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        y_pred = torch.cat([i['y_pred'] for i in outputs], dim=0).cpu().numpy()\n",
    "        y_true = torch.cat([i['y_true'] for i in outputs], dim=0).cpu().numpy()\n",
    "        \n",
    "        roc_list = []\n",
    "        for i in range(y_true.shape[1]):\n",
    "            #AUC is only defined when there is at least one positive data.\n",
    "            if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == -1) > 0:\n",
    "                is_valid = y_true[:,i]**2 > 0\n",
    "                roc_list.append(roc_auc_score((y_true[is_valid,i] + 1)/2, y_pred[is_valid,i]))\n",
    "\n",
    "        if len(roc_list) < y_true.shape[1]:\n",
    "            print(\"Some target is missing!\")\n",
    "            print(\"Missing ratio: %f\" %(1 - float(len(roc_list))/y_true.shape[1]))\n",
    "        mean_auroc = sum(roc_list) / len(roc_list)\n",
    "        print()\n",
    "        print('auroc:', mean_auroc) #y_true.shape[1]\n",
    "        if self.dataset_name == 'ogbg-molpcba':\n",
    "            mask = ~torch.isnan(y_true)\n",
    "            loss = self.loss_fn(y_pred[mask], y_true[mask])\n",
    "            self.log('valid_ap', loss, sync_dist=True)\n",
    "        else:\n",
    "            input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "            try:\n",
    "                self.log('valid_' + self.metric, mean_auroc, sync_dist=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def test_step(self, batched_data, batch_idx):\n",
    "        if self.dataset_name in ['PCQM4M-LSC', 'ZINC']:\n",
    "            y_pred = self(batched_data).view(-1)\n",
    "            y_true = batched_data.y.view(-1)\n",
    "        else:\n",
    "            y_pred = self(batched_data)\n",
    "            y_true = batched_data.y\n",
    "        return {\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y_true,\n",
    "            'idx': batched_data.idx,\n",
    "        }\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        y_pred = torch.cat([i['y_pred'] for i in outputs]).cpu().numpy()\n",
    "        y_true = torch.cat([i['y_true'] for i in outputs]).cpu().numpy()\n",
    "        roc_list = []\n",
    "        for i in range(y_true.shape[1]):\n",
    "            #AUC is only defined when there is at least one positive data.\n",
    "            if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == -1) > 0:\n",
    "                is_valid = y_true[:,i]**2 > 0\n",
    "                roc_list.append(roc_auc_score((y_true[is_valid,i] + 1)/2, y_pred[is_valid,i]))\n",
    "\n",
    "        if len(roc_list) < y_true.shape[1]:\n",
    "            print(\"Some target is missing!\")\n",
    "            print(\"Missing ratio: %f\" %(1 - float(len(roc_list))/y_true.shape[1]))\n",
    "        mean_auroc = sum(roc_list) / len(roc_list)\n",
    "        print()\n",
    "        print('auroc:', mean_auroc) #y_true.shape[1]\n",
    "        if self.dataset_name == 'PCQM4M-LSC':\n",
    "            result = y_pred.cpu().float().numpy()\n",
    "            idx = torch.cat([i['idx'] for i in outputs])\n",
    "            torch.save(result, 'y_pred.pt')\n",
    "            torch.save(idx, 'idx.pt')\n",
    "            exit(0)\n",
    "        input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "        self.log('test_' + self.metric, mean_auroc, sync_dist=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.peak_lr, weight_decay=self.weight_decay)\n",
    "        lr_scheduler = {\n",
    "            'scheduler': PolynomialDecayLR(\n",
    "                optimizer,\n",
    "                warmup_updates=self.warmup_updates,\n",
    "                tot_updates=self.tot_updates,\n",
    "                lr=self.peak_lr,\n",
    "                end_lr=self.end_lr,\n",
    "                power=1.0,\n",
    "            ),\n",
    "            'name': 'learning_rate',\n",
    "            'interval': 'step',\n",
    "            'frequency': 1,\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"Graphormer\")\n",
    "        parser.add_argument('--n_layers', type=int, default=6)\n",
    "        parser.add_argument('--num_heads', type=int, default=32)\n",
    "        parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "        parser.add_argument('--ffn_dim', type=int, default=512)\n",
    "        parser.add_argument('--intput_dropout_rate', type=float, default=0.1)\n",
    "        parser.add_argument('--dropout_rate', type=float, default=0.1)\n",
    "        parser.add_argument('--weight_decay', type=float, default=0.01)\n",
    "        parser.add_argument('--attention_dropout_rate',\n",
    "                            type=float, default=0.1)\n",
    "        parser.add_argument('--checkpoint_path', type=str, default='')\n",
    "        parser.add_argument('--warmup_updates', type=int, default=60000)\n",
    "        parser.add_argument('--tot_updates', type=int, default=1000000)\n",
    "        parser.add_argument('--peak_lr', type=float, default=2e-4)\n",
    "        parser.add_argument('--end_lr', type=float, default=1e-9)\n",
    "        parser.add_argument('--edge_type', type=str, default='multi_hop')\n",
    "        parser.add_argument('--validate', action='store_true', default=False)\n",
    "        parser.add_argument('--test', action='store_true', default=False)\n",
    "        parser.add_argument('--flag', action='store_true')\n",
    "        parser.add_argument('--flag_m', type=int, default=3)\n",
    "        parser.add_argument('--flag_step_size', type=float, default=1e-3)\n",
    "        parser.add_argument('--flag_mag', type=float, default=1e-3)\n",
    "        return parent_parser\n",
    "\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size, ffn_size, dropout_rate):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(hidden_size, ffn_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layer2 = nn.Linear(ffn_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, attention_dropout_rate, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.att_size = att_size = hidden_size // num_heads\n",
    "        self.scale = att_size ** -0.5\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.1))\n",
    "        self.linear_q = nn.Linear(hidden_size, num_heads * att_size)\n",
    "        self.linear_k = nn.Linear(hidden_size, num_heads * att_size)\n",
    "        self.linear_v = nn.Linear(hidden_size, num_heads * att_size)\n",
    "        self.att_dropout = nn.Dropout(attention_dropout_rate)\n",
    "\n",
    "        self.output_layer = nn.Linear(num_heads * att_size, hidden_size)\n",
    "\n",
    "    def forward(self, q, k, v, attn_bias=None):\n",
    "        orig_q_size = q.size()\n",
    "\n",
    "        d_k = self.att_size\n",
    "        d_v = self.att_size\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # head_i = Attention(Q(W^Q)_i, K(W^K)_i, V(W^V)_i)\n",
    "        q = self.linear_q(q).view(batch_size, -1, self.num_heads, d_k)\n",
    "        k = self.linear_k(k).view(batch_size, -1, self.num_heads, d_k)\n",
    "        v = self.linear_v(v).view(batch_size, -1, self.num_heads, d_v)\n",
    "\n",
    "        q = q.transpose(1, 2)                  # [b, h, q_len, d_k]\n",
    "        v = v.transpose(1, 2)                  # [b, h, v_len, d_v]\n",
    "        k = k.transpose(1, 2).transpose(2, 3)  # [b, h, d_k, k_len]\n",
    "\n",
    "        # Scaled Dot-Product Attention.\n",
    "        # Attention(Q, K, V) = softmax((QK^T)/sqrt(d_k))V\n",
    "        q = q * self.scale\n",
    "        x = torch.matmul(q, k)  # [b, h, q_len, k_len]\n",
    "        if attn_bias is not None:\n",
    "            x = self.alpha * x + (1 - self.alpha)* attn_bias\n",
    "            #x = x + attn_bias\n",
    "\n",
    "        x = torch.softmax(x, dim=3)\n",
    "        x = self.att_dropout(x)\n",
    "        x = x.matmul(v)  # [b, h, q_len, attn]\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous()  # [b, q_len, h, attn]\n",
    "        x = x.view(batch_size, -1, self.num_heads * d_v)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        assert x.size() == orig_q_size\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, ffn_size, dropout_rate, attention_dropout_rate, num_heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention_norm = nn.LayerNorm(hidden_size)\n",
    "        self.self_attention = MultiHeadAttention(\n",
    "            hidden_size, attention_dropout_rate, num_heads)\n",
    "        self.self_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.ffn_norm = nn.LayerNorm(hidden_size)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, ffn_size, dropout_rate)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, attn_bias=None):\n",
    "        y = self.self_attention_norm(x)\n",
    "        y = self.self_attention(y, y, y, attn_bias)\n",
    "        y = self.self_attention_dropout(y)\n",
    "        x = x + y\n",
    "\n",
    "        y = self.ffn_norm(x)\n",
    "        y = self.ffn(y)\n",
    "        y = self.ffn_dropout(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17f6a7-66c7-498b-be00-8d37197f9959",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_args', '_get_kwargs', 'accelerator', 'accumulate_grad_batches', 'amp_backend', 'amp_level', 'attention_dropout_rate', 'auto_lr_find', 'auto_scale_batch_size', 'auto_select_gpus', 'batch_size', 'benchmark', 'check_val_every_n_epoch', 'checkpoint_callback', 'checkpoint_path', 'dataset_name', 'default_root_dir', 'detect_anomaly', 'deterministic', 'devices', 'dropout_rate', 'edge_type', 'enable_checkpointing', 'enable_model_summary', 'enable_progress_bar', 'end_lr', 'fast_dev_run', 'ffn_dim', 'flag', 'flag_m', 'flag_mag', 'flag_step_size', 'flush_logs_every_n_steps', 'gpus', 'gradient_clip_algorithm', 'gradient_clip_val', 'hidden_dim', 'intput_dropout_rate', 'ipus', 'limit_predict_batches', 'limit_test_batches', 'limit_train_batches', 'limit_val_batches', 'log_every_n_steps', 'log_gpu_memory', 'logger', 'max_epochs', 'max_steps', 'max_time', 'min_epochs', 'min_steps', 'move_metrics_to_cpu', 'multi_hop_max_dist', 'multiple_trainloader_mode', 'n_layers', 'num_heads', 'num_nodes', 'num_processes', 'num_sanity_val_steps', 'num_workers', 'overfit_batches', 'peak_lr', 'plugins', 'precision', 'prepare_data_per_node', 'process_position', 'profiler', 'progress_bar_refresh_rate', 'reload_dataloaders_every_epoch', 'reload_dataloaders_every_n_epochs', 'replace_sampler_ddp', 'resume_from_checkpoint', 'seed', 'spatial_pos_max', 'stochastic_weight_avg', 'strategy', 'sync_batchnorm', 'terminate_on_nan', 'test', 'tot_updates', 'tpu_cores', 'track_grad_norm', 'val_check_interval', 'validate', 'warmup_updates', 'weight_decay', 'weights_save_path', 'weights_summary']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yliu/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params: 12556370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_dataloader) 13\n",
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yliu/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 12/13 [00:07<00:00,  1.84it/s]\n",
      "auroc: 0.8427785838513887\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_AUROC': 0.8427785634994507}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 13/13 [00:07<00:00,  1.69it/s]"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pprint import pprint\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = Graphormer.add_model_specific_args(parser)\n",
    "parser = GraphDataModule.add_argparse_args(parser)\n",
    "parser.parse_args(['--auto_select_gpus', 'True'])\n",
    "args, _ = parser.parse_known_args()\n",
    "args.gpus=1\n",
    "args.auto_select_gpus=True\n",
    "args.batch_size = 64\n",
    "args.max_epochs = 100\n",
    "args.n_layers = 6\n",
    "args.test = 'test'\n",
    "\n",
    "args.dataset = \"Tox21\"\n",
    "print(dir(args))\n",
    "args.max_steps = args.tot_updates + 1\n",
    "args.checkpoint_path = \"lightning_logs/checkpoints_alpha/Tox21-epoch=098-valid_AUROC=0.8679.ckpt\"\n",
    "\n",
    "if not args.test and not args.validate:\n",
    "    print(args)\n",
    "pl.seed_everything(args.seed)\n",
    "\n",
    "# ------------\n",
    "# data\n",
    "# ------------\n",
    "dm = GraphDataModule.from_argparse_args(args)\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "if args.checkpoint_path != '':\n",
    "    model = Graphormer.load_from_checkpoint(\n",
    "        args.checkpoint_path,\n",
    "        strict=False,\n",
    "        n_layers=args.n_layers,\n",
    "        num_heads=args.num_heads,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        attention_dropout_rate=args.attention_dropout_rate,\n",
    "        dropout_rate=args.dropout_rate,\n",
    "        intput_dropout_rate=args.intput_dropout_rate,\n",
    "        weight_decay=args.weight_decay,\n",
    "        ffn_dim=args.ffn_dim,\n",
    "        dataset_name=dm.dataset_name,\n",
    "        warmup_updates=args.warmup_updates,\n",
    "        tot_updates=args.tot_updates,\n",
    "        peak_lr=args.peak_lr,\n",
    "        end_lr=args.end_lr,\n",
    "        edge_type=args.edge_type,\n",
    "        multi_hop_max_dist=args.multi_hop_max_dist,\n",
    "        flag=args.flag,\n",
    "        flag_m=args.flag_m,\n",
    "        flag_step_size=args.flag_step_size,\n",
    "    )\n",
    "else:\n",
    "    model = Graphormer(\n",
    "        n_layers=args.n_layers,\n",
    "        num_heads=args.num_heads,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        attention_dropout_rate=args.attention_dropout_rate,\n",
    "        dropout_rate=args.dropout_rate,\n",
    "        intput_dropout_rate=args.intput_dropout_rate,\n",
    "        weight_decay=args.weight_decay,\n",
    "        ffn_dim=args.ffn_dim,\n",
    "        dataset_name=dm.dataset_name,\n",
    "        warmup_updates=args.warmup_updates,\n",
    "        tot_updates=args.tot_updates,\n",
    "        peak_lr=args.peak_lr,\n",
    "        end_lr=args.end_lr,\n",
    "        edge_type=args.edge_type,\n",
    "        multi_hop_max_dist=args.multi_hop_max_dist,\n",
    "        flag=args.flag,\n",
    "        flag_m=args.flag_m,\n",
    "        flag_step_size=args.flag_step_size,\n",
    "    )\n",
    "if not args.test and not args.validate:\n",
    "    print(model)\n",
    "print('total params:', sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "#metric = 'valid_' + get_dataset(dm.dataset_name)['metric']\n",
    "metric = 'valid_' + \"AUROC\"\n",
    "#dirpath = args.default_root_dir + f'/lightning_logs/checkpoints'\n",
    "dirpath = './' + f'/lightning_logs/checkpoints_alpha'\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=metric,\n",
    "    dirpath=dirpath,\n",
    "    filename=dm.dataset_name + '-{epoch:03d}-{' + str(metric) + ':.4f}',\n",
    "    save_top_k=100,\n",
    "    mode=get_dataset(dm.dataset_name)['metric_mode'],\n",
    "    save_last=True,\n",
    ")\n",
    "if not args.test and not args.validate and os.path.exists(dirpath + '/last.ckpt'):\n",
    "    args.resume_from_checkpoint = dirpath + '/last.ckpt'\n",
    "    print('args.resume_from_checkpoint', args.resume_from_checkpoint)\n",
    "trainer = pl.Trainer.from_argparse_args(args)\n",
    "trainer.callbacks.append(checkpoint_callback)\n",
    "trainer.callbacks.append(LearningRateMonitor(logging_interval='step'))\n",
    "\n",
    "if args.test:\n",
    "    result = trainer.test(model, datamodule=dm)\n",
    "    pprint(result)\n",
    "elif args.validate:\n",
    "    result = trainer.validate(model, datamodule=dm)\n",
    "    pprint(result)\n",
    "else:\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f07d6e-eddc-40af-8e46-94680a431dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu] *",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
